{
  "title": "THA-Net: AI for Hip Replacement Planning",
  "slug": "tha-net-hip-templating-ai",
  "description": "An AI model (THA-Net) that generates realistic post-operative X-rays from pre-operative images for total hip arthroplasty planning.",
  "abstract": "Planning for a total hip replacement (THA) usually involves looking at radiology imaging and figuring out the right implant sizes – a process called templating. But what if you could actually *see* what the final surgery might look like on an X-ray *before* even starting? That's the idea behind THA-Net, a project I worked on with a fantastic team.\n\nTHA-Net is basically a deep learning AI that specializes in 'inpainting'. You give it a patient's pre-surgery pelvic X-ray, and it intelligently replaces the hip joint area with realistic-looking THA implants, generating a synthetic 'after' picture. It's pretty smart – it can either predict the implants it thinks are best based on its training, or we can tell it exactly which implants the surgeon plans to use, and it will generate the image based on that specific choice.\n\nWe trained this beast on a massive dataset from Mayo Clinic – over 350,000 X-ray pairs from more than 14,000 patients! When we tested it, the results were kind of mind-blowing. Surgeons reviewing the images couldn't reliably tell the difference between our AI-generated X-rays and real post-op ones. Even cooler, when they rated the 'quality' of the surgery shown (like implant positioning), the synthetic images generated by THA-Net often scored *higher* than the actual average real-world outcomes it learned from!\n\nWe think this could be a game-changer for patient-specific surgical planning. Imagine fine-tuning the plan by visualizing outcomes, or even using this to help guide robotic surgery systems or augmented reality tools in the OR. The code itself is proprietary, so unfortunately I can't share that, but you can check out the published paper linked below and even try out an online demo! And of course, a huge thank you to my co-authors Bardia Khosravi, John P. Mickley, Bradley J. Erickson, Michael J. Taunton, and Cody C. Wyles – this was truly a team effort.",
  "year": 2023,
  "technologies": ["Python", "PyTorch", "Deep Learning", "Diffusion Models"],
  "projectTags": [
    "AI & ML",
    "Generative Models",
    "Inpainting",
    "Medical Imaging",
    "Radiography",
    "X-ray",
    "Total Hip Arthroplasty (THA)",
    "Diffusion Models",
    "Orthopedics",
    "Surgical Planning",
    "Templating",
    "Healthcare AI",
    "Computer Vision"
  ],
  "imageUrl": "https://res.cloudinary.com/dzqiwtbg6/image/upload/v1743825529/0af38983-b6bc-4e80-91a6-b0d81e6295f3.png",
  "publicationUrl": "https://www.sciencedirect.com/science/article/abs/pii/S0883540323008720",
  "videoUrl": "https://www.youtube.com/watch?v=snpez7LaycE"
}
